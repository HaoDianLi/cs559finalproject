{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>HomePlanet</th>\n",
       "      <th>CryoSleep</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Destination</th>\n",
       "      <th>Age</th>\n",
       "      <th>VIP</th>\n",
       "      <th>RoomService</th>\n",
       "      <th>FoodCourt</th>\n",
       "      <th>ShoppingMall</th>\n",
       "      <th>Spa</th>\n",
       "      <th>VRDeck</th>\n",
       "      <th>Name</th>\n",
       "      <th>Transported</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0001_01</td>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>B/0/P</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>39.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Maham Ofracculy</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0002_01</td>\n",
       "      <td>Earth</td>\n",
       "      <td>False</td>\n",
       "      <td>F/0/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>24.0</td>\n",
       "      <td>False</td>\n",
       "      <td>109.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>549.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>Juanna Vines</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0003_01</td>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>A/0/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>58.0</td>\n",
       "      <td>True</td>\n",
       "      <td>43.0</td>\n",
       "      <td>3576.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6715.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>Altark Susent</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0003_02</td>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>A/0/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>33.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1283.0</td>\n",
       "      <td>371.0</td>\n",
       "      <td>3329.0</td>\n",
       "      <td>193.0</td>\n",
       "      <td>Solam Susent</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0004_01</td>\n",
       "      <td>Earth</td>\n",
       "      <td>False</td>\n",
       "      <td>F/1/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>16.0</td>\n",
       "      <td>False</td>\n",
       "      <td>303.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>151.0</td>\n",
       "      <td>565.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Willy Santantines</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  PassengerId HomePlanet CryoSleep  Cabin  Destination   Age    VIP  \\\n",
       "0     0001_01     Europa     False  B/0/P  TRAPPIST-1e  39.0  False   \n",
       "1     0002_01      Earth     False  F/0/S  TRAPPIST-1e  24.0  False   \n",
       "2     0003_01     Europa     False  A/0/S  TRAPPIST-1e  58.0   True   \n",
       "3     0003_02     Europa     False  A/0/S  TRAPPIST-1e  33.0  False   \n",
       "4     0004_01      Earth     False  F/1/S  TRAPPIST-1e  16.0  False   \n",
       "\n",
       "   RoomService  FoodCourt  ShoppingMall     Spa  VRDeck               Name  \\\n",
       "0          0.0        0.0           0.0     0.0     0.0    Maham Ofracculy   \n",
       "1        109.0        9.0          25.0   549.0    44.0       Juanna Vines   \n",
       "2         43.0     3576.0           0.0  6715.0    49.0      Altark Susent   \n",
       "3          0.0     1283.0         371.0  3329.0   193.0       Solam Susent   \n",
       "4        303.0       70.0         151.0   565.0     2.0  Willy Santantines   \n",
       "\n",
       "   Transported  \n",
       "0        False  \n",
       "1         True  \n",
       "2        False  \n",
       "3        False  \n",
       "4         True  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Submission to Kaggle Titanic Competition\n",
    "import pandas as pd\n",
    "DF = pd.read_csv('train.csv')\n",
    "test_DF = pd.read_csv('test.csv')\n",
    "DF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "\n",
    "# Preprocessing\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler, StandardScaler\n",
    "\n",
    "# Splitting\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Models\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier,GradientBoostingClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "\n",
    "\n",
    "\n",
    "# Metrics\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "# Grid Search\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId      object\n",
       "HomePlanet       object\n",
       "CryoSleep        object\n",
       "Cabin            object\n",
       "Destination      object\n",
       "Age             float64\n",
       "VIP              object\n",
       "RoomService     float64\n",
       "FoodCourt       float64\n",
       "ShoppingMall    float64\n",
       "Spa             float64\n",
       "VRDeck          float64\n",
       "Name             object\n",
       "Transported        bool\n",
       "dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DF.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>RoomService</th>\n",
       "      <th>FoodCourt</th>\n",
       "      <th>ShoppingMall</th>\n",
       "      <th>Spa</th>\n",
       "      <th>VRDeck</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>8514.000000</td>\n",
       "      <td>8512.000000</td>\n",
       "      <td>8510.000000</td>\n",
       "      <td>8485.000000</td>\n",
       "      <td>8510.000000</td>\n",
       "      <td>8505.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>28.827930</td>\n",
       "      <td>224.687617</td>\n",
       "      <td>458.077203</td>\n",
       "      <td>173.729169</td>\n",
       "      <td>311.138778</td>\n",
       "      <td>304.854791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>14.489021</td>\n",
       "      <td>666.717663</td>\n",
       "      <td>1611.489240</td>\n",
       "      <td>604.696458</td>\n",
       "      <td>1136.705535</td>\n",
       "      <td>1145.717189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>19.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>27.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>38.000000</td>\n",
       "      <td>47.000000</td>\n",
       "      <td>76.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>59.000000</td>\n",
       "      <td>46.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>79.000000</td>\n",
       "      <td>14327.000000</td>\n",
       "      <td>29813.000000</td>\n",
       "      <td>23492.000000</td>\n",
       "      <td>22408.000000</td>\n",
       "      <td>24133.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Age   RoomService     FoodCourt  ShoppingMall           Spa  \\\n",
       "count  8514.000000   8512.000000   8510.000000   8485.000000   8510.000000   \n",
       "mean     28.827930    224.687617    458.077203    173.729169    311.138778   \n",
       "std      14.489021    666.717663   1611.489240    604.696458   1136.705535   \n",
       "min       0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%      19.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "50%      27.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "75%      38.000000     47.000000     76.000000     27.000000     59.000000   \n",
       "max      79.000000  14327.000000  29813.000000  23492.000000  22408.000000   \n",
       "\n",
       "             VRDeck  \n",
       "count   8505.000000  \n",
       "mean     304.854791  \n",
       "std     1145.717189  \n",
       "min        0.000000  \n",
       "25%        0.000000  \n",
       "50%        0.000000  \n",
       "75%       46.000000  \n",
       "max    24133.000000  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DF.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId       0\n",
       "HomePlanet      201\n",
       "CryoSleep       217\n",
       "Cabin           199\n",
       "Destination     182\n",
       "Age             179\n",
       "VIP             203\n",
       "RoomService     181\n",
       "FoodCourt       183\n",
       "ShoppingMall    208\n",
       "Spa             183\n",
       "VRDeck          188\n",
       "Name            200\n",
       "Transported       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DF.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "PASSENGER_ID = test_DF[['PassengerId']]\n",
    "DF.drop(['PassengerId', 'Cabin', 'Name'], axis=1, inplace=True)\n",
    "test_DF.drop(['PassengerId', 'Cabin', 'Name'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "labels = test_DF.columns\n",
    "for col in labels:\n",
    "    if col in ['Age', 'RoomService','FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck']:\n",
    "        DF[col].fillna(DF[col].median(), inplace=True)\n",
    "        test_DF[col].fillna(DF[col].median(), inplace=True)\n",
    "    else:\n",
    "        DF[col].fillna(DF[col].mode()[0], inplace=True)\n",
    "        test_DF[col].fillna(DF[col].mode()[0], inplace=True)\n",
    "for col in labels:\n",
    "    if DF[col].dtype == 'O':\n",
    "        encoder = LabelEncoder()\n",
    "        DF[col] = encoder.fit_transform(DF[col])\n",
    "        test_DF[col] = encoder.transform(test_DF[col])\n",
    "        \n",
    "    elif DF[col].dtype == 'bool':\n",
    "        DF[col] = DF[col].astype('int')\n",
    "        test_DF[col] = test_DF[col].astype('int')\n",
    "encoder = LabelEncoder()\n",
    "DF['Transported'] = DF['Transported'].astype('int')\n",
    "labels_MM = ['Age']\n",
    "labels_SS = ['RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "mm_scaler = MinMaxScaler()\n",
    "ss_scaler = StandardScaler()\n",
    "\n",
    "DF[labels_MM] = mm_scaler.fit_transform(DF[labels_MM])\n",
    "test_DF[labels_MM] = mm_scaler.transform(test_DF[labels_MM])\n",
    "\n",
    "\n",
    "DF[labels_SS] = ss_scaler.fit_transform(DF[labels_SS])\n",
    "test_DF[labels_SS] = ss_scaler.transform(test_DF[labels_SS])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, ..., 1, 0, 1])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y =DF.drop('Transported', axis=1), np.array(DF[['Transported']]).reshape(-1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.10, stratify=y)\n",
    "\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_accuracy = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Gaussian Naive Bayes : 0.7057471264367816\n"
     ]
    }
   ],
   "source": [
    "ensemble_models = GaussianNB()\n",
    "predictor_gnb = ensemble_models.fit(X_train, y_train)\n",
    "y_pred_gnb = predictor_gnb.predict(X_test)\n",
    "accuracy_gnb = accuracy_score(y_test, y_pred_gnb)\n",
    "model_accuracy['naive_bayes'] = accuracy_gnb\n",
    "print(\"Accuracy of Gaussian Naive Bayes :\",accuracy_gnb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Logistic Regression : 0.7701149425287356\n"
     ]
    }
   ],
   "source": [
    "ensemble_models = LogisticRegression()\n",
    "predictor_lr = ensemble_models.fit(X_train, y_train)\n",
    "y_pred_lr = predictor_lr.predict(X_test)\n",
    "accuracy_lr = accuracy_score(y_test, y_pred_lr)\n",
    "model_accuracy['logistic_regression'] = accuracy_lr\n",
    "print(\"Accuracy of Logistic Regression :\",accuracy_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of SVC : 0.774712643678161\n"
     ]
    }
   ],
   "source": [
    "ensemble_models = SVC()\n",
    "predictor_svc = ensemble_models.fit(X_train, y_train)\n",
    "y_pred_svc = predictor_svc.predict(X_test)\n",
    "accuracy_svc = accuracy_score(y_test, y_pred_svc)\n",
    "model_accuracy['SVC'] = accuracy_svc\n",
    "print(\"Accuracy of SVC :\",accuracy_svc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree : 0.7379310344827587\n"
     ]
    }
   ],
   "source": [
    "ensemble_models = DecisionTreeClassifier()\n",
    "predictor_dtc = ensemble_models.fit(X_train, y_train)\n",
    "y_pred_dtc = predictor_dtc.predict(X_test)\n",
    "accuracy_dtc = accuracy_score(y_test, y_pred_dtc)\n",
    "model_accuracy['decision_tree'] = accuracy_dtc\n",
    "print(\"Accuracy of Decision Tree :\",accuracy_dtc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Random Tree : 0.7885057471264367\n"
     ]
    }
   ],
   "source": [
    "ensemble_models = RandomForestClassifier()\n",
    "predictor_rtc = ensemble_models.fit(X_train, y_train)\n",
    "y_pred_rtc = predictor_rtc.predict(X_test)\n",
    "accuracy_rtc = accuracy_score(y_test, y_pred_rtc)\n",
    "model_accuracy['random_forest'] = accuracy_rtc\n",
    "print(\"Accuracy of Random Tree :\",accuracy_rtc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Gradient Boost : 0.7954022988505747\n"
     ]
    }
   ],
   "source": [
    "ensemble_models = GradientBoostingClassifier()\n",
    "predictor_gb = ensemble_models.fit(X_train, y_train)\n",
    "y_pred_gb = predictor_gb.predict(X_test)\n",
    "accuracy_gb = accuracy_score(y_test, y_pred_gb)\n",
    "model_accuracy['gradient_boost'] = accuracy_gb\n",
    "print(\"Accuracy of Gradient Boost :\",accuracy_gb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of MLP : 0.7965517241379311\n"
     ]
    }
   ],
   "source": [
    "ensemble_models = MLPClassifier()\n",
    "predictor_mlp = ensemble_models.fit(X_train, y_train)\n",
    "y_pred_mlp = predictor_mlp.predict(X_test)\n",
    "accuracy_mlp = accuracy_score(y_test, y_pred_mlp)\n",
    "model_accuracy['MLP'] = accuracy_mlp\n",
    "print(\"Accuracy of MLP :\",accuracy_mlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of LDA : 0.7390804597701149\n"
     ]
    }
   ],
   "source": [
    "ensemble_models = LinearDiscriminantAnalysis()\n",
    "predictor_lda = ensemble_models.fit(X_train, y_train)\n",
    "y_pred_lda = predictor_lda.predict(X_test)\n",
    "accuracy_lda = accuracy_score(y_test, y_pred_lda)\n",
    "model_accuracy['LDA'] = accuracy_lda\n",
    "print(\"Accuracy of LDA :\",accuracy_lda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of KNN : 0.774712643678161\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lihao\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n"
     ]
    }
   ],
   "source": [
    "ensemble_models = KNeighborsClassifier()\n",
    "predictor_knn = ensemble_models.fit(X_train, y_train)\n",
    "y_pred_knn = predictor_knn.predict(X_test)\n",
    "accuracy_knn = accuracy_score(y_test, y_pred_knn)\n",
    "model_accuracy['KNN'] = accuracy_knn\n",
    "print(\"Accuracy of KNN :\",accuracy_knn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of ADA : 0.7862068965517242\n"
     ]
    }
   ],
   "source": [
    "ensemble_models = AdaBoostClassifier()\n",
    "predictor_ada = ensemble_models.fit(X_train, y_train)\n",
    "y_pred_ada = predictor_ada.predict(X_test)\n",
    "accuracy_ada = accuracy_score(y_test, y_pred_ada)\n",
    "model_accuracy['ADA'] = accuracy_ada\n",
    "print(\"Accuracy of ADA :\",accuracy_ada)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'naive_bayes': 0.7057471264367816,\n",
       " 'logistic_regression': 0.7701149425287356,\n",
       " 'SVC': 0.774712643678161,\n",
       " 'decision_tree': 0.7379310344827587,\n",
       " 'random_forest': 0.7885057471264367,\n",
       " 'gradient_boost': 0.7954022988505747,\n",
       " 'MLP': 0.7965517241379311,\n",
       " 'LDA': 0.7390804597701149,\n",
       " 'KNN': 0.774712643678161,\n",
       " 'ADA': 0.7862068965517242}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lihao\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy scores for the first ensemble: 0.7862068965517242\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lihao\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n"
     ]
    }
   ],
   "source": [
    "voting_ensemble = VotingClassifier(estimators= [('GB', predictor_gb), ('MLP', predictor_mlp), ('SVC', predictor_svc), ('GNB',predictor_gnb), ('LR',predictor_lr), ('DT', predictor_dtc), ('RT', predictor_rtc), ('LDA', predictor_lda), ('KNN', predictor_knn), ('ADA', predictor_ada)],voting = 'hard')\n",
    "\n",
    "ensemble_predictor = voting_ensemble.fit(X_train, y_train)\n",
    "\n",
    "y_pred = ensemble_predictor.predict(X_test)\n",
    "print(f'Accuracy scores for the first ensemble: {accuracy_score(y_test, y_pred)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('GB', GradientBoostingClassifier()),\n",
       "                             ('MLP', MLPClassifier()), ('SVC', SVC()),\n",
       "                             ('GNB', GaussianNB()),\n",
       "                             ('LR', LogisticRegression()),\n",
       "                             ('DT', DecisionTreeClassifier()),\n",
       "                             ('RT', RandomForestClassifier()),\n",
       "                             ('LDA', LinearDiscriminantAnalysis()),\n",
       "                             ('KNN', KNeighborsClassifier()),\n",
       "                             ('ADA', AdaBoostClassifier())])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ensemble_predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lihao\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n"
     ]
    }
   ],
   "source": [
    "submission = ensemble_predictor.predict(test_DF)\n",
    "\n",
    "data = {'PassengerId': np.array(PASSENGER_ID).reshape(len(PASSENGER_ID)),\n",
    "        'Transported': np.array(submission).astype('bool')}\n",
    "\n",
    "submission_df = pd.DataFrame(data=data).reset_index()\n",
    "submission_df.drop(columns=['index'], inplace=True, axis=1)\n",
    "# submission_df.to_csv(\"submission.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Class Submission\n",
    "from pandas import read_csv\n",
    "from sklearn.model_selection import train_test_split\n",
    "_DF = read_csv('train_.csv')\n",
    "_test_DF = read_csv('test_.csv')\n",
    "_validation_DF = read_csv('validation_.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0        int64\n",
       "PassengerId      object\n",
       "HomePlanet       object\n",
       "CryoSleep        object\n",
       "Cabin            object\n",
       "Destination      object\n",
       "Age             float64\n",
       "VIP              object\n",
       "RoomService     float64\n",
       "FoodCourt       float64\n",
       "ShoppingMall    float64\n",
       "Spa             float64\n",
       "VRDeck          float64\n",
       "Name             object\n",
       "Transported        bool\n",
       "dtype: object"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_DF.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0        0\n",
       "PassengerId       0\n",
       "HomePlanet      142\n",
       "CryoSleep       156\n",
       "Cabin           144\n",
       "Destination     122\n",
       "Age             130\n",
       "VIP             152\n",
       "RoomService     126\n",
       "FoodCourt       126\n",
       "ShoppingMall    151\n",
       "Spa             118\n",
       "VRDeck          129\n",
       "Name            145\n",
       "Transported       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_DF.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "PASSENGER_ID = _test_DF[['PassengerId']]\n",
    "_DF.drop(['PassengerId', 'Cabin', 'Name'], axis=1, inplace=True)\n",
    "_test_DF.drop(['PassengerId', 'Cabin', 'Name'], axis=1, inplace=True)\n",
    "_validation_DF.drop(['PassengerId', 'Cabin', 'Name'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "labels = _test_DF.columns\n",
    "for col in labels:\n",
    "    if col in ['Age', 'RoomService','FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck']:\n",
    "        _DF[col].fillna(_DF[col].median(), inplace=True)\n",
    "        _test_DF[col].fillna(_DF[col].median(), inplace=True)\n",
    "        _validation_DF[col].fillna(_DF[col].median(), inplace=True)\n",
    "    else:\n",
    "        _DF[col].fillna(_DF[col].mode()[0], inplace=True)\n",
    "        _test_DF[col].fillna(_DF[col].mode()[0], inplace=True)\n",
    "        _validation_DF[col].fillna(_DF[col].mode()[0], inplace=True)\n",
    "for col in labels:\n",
    "    if _DF[col].dtype == 'O':\n",
    "        encoder = LabelEncoder()\n",
    "        _DF[col] = encoder.fit_transform(_DF[col])\n",
    "        _test_DF[col] = encoder.transform(_test_DF[col])\n",
    "        _validation_DF[col] = encoder.transform(_validation_DF[col])\n",
    "        \n",
    "    elif _DF[col].dtype == 'bool':\n",
    "        _DF[col] = _DF[col].astype('int')\n",
    "        _test_DF[col] = _test_DF[col].astype('int')\n",
    "        _validation_DF[col] = _validation_DF[col].astype('int')\n",
    "encoder = LabelEncoder()\n",
    "_DF['Transported'] = _DF['Transported'].astype('int')\n",
    "labels_MM = ['Age']\n",
    "labels_SS = ['RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unnamed: 0        int64\n",
      "HomePlanet        int32\n",
      "CryoSleep         int32\n",
      "Destination       int32\n",
      "Age             float64\n",
      "VIP               int32\n",
      "RoomService     float64\n",
      "FoodCourt       float64\n",
      "ShoppingMall    float64\n",
      "Spa             float64\n",
      "VRDeck          float64\n",
      "Transported       int32\n",
      "dtype: object\n",
      "Unnamed: 0      0\n",
      "HomePlanet      0\n",
      "CryoSleep       0\n",
      "Destination     0\n",
      "Age             0\n",
      "VIP             0\n",
      "RoomService     0\n",
      "FoodCourt       0\n",
      "ShoppingMall    0\n",
      "Spa             0\n",
      "VRDeck          0\n",
      "Transported     0\n",
      "dtype: int64\n",
      "Unnamed: 0      0\n",
      "HomePlanet      0\n",
      "CryoSleep       0\n",
      "Destination     0\n",
      "Age             0\n",
      "VIP             0\n",
      "RoomService     0\n",
      "FoodCourt       0\n",
      "ShoppingMall    0\n",
      "Spa             0\n",
      "VRDeck          0\n",
      "Transported     0\n",
      "dtype: int64\n",
      "Unnamed: 0      0\n",
      "HomePlanet      0\n",
      "CryoSleep       0\n",
      "Destination     0\n",
      "Age             0\n",
      "VIP             0\n",
      "RoomService     0\n",
      "FoodCourt       0\n",
      "ShoppingMall    0\n",
      "Spa             0\n",
      "VRDeck          0\n",
      "Transported     0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(_DF.dtypes)\n",
    "print(_DF.isnull().sum())\n",
    "print(_test_DF.isnull().sum())\n",
    "print(_validation_DF.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# _X_train, _X_test, _y_train, _y_test = train_test_split(_DF.drop(['Transported'], axis=1), _DF['Transported'], test_size=0.2, random_state=42)\n",
    "_X_train = _DF.drop(['Transported'], axis=1)\n",
    "_y_train = _DF['Transported']\n",
    "_X_test = _validation_DF.drop(['Transported'], axis=1)\n",
    "_y_test = _validation_DF['Transported']\n",
    "_X_final_test = _test_DF.drop(['Transported'], axis=1)\n",
    "_y_final_test = _test_DF['Transported']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Olof Persson's code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score: 0.6979888391906283\n",
      "Best Hyperparameters: {'var_smoothing': 1e-08}\n"
     ]
    }
   ],
   "source": [
    "#Parametric model\n",
    "#Naive Bayes\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "#create a naive bayes classifier with grid search parameters for tuning\n",
    "\n",
    "model = GaussianNB()\n",
    "# define grid search\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "# define search space\n",
    "space = dict()\n",
    "space['var_smoothing'] = [1e-05,1e-06,1e-07,1e-08,1e-09, 1e-10, 1e-11, 1e-12, 1e-13]\n",
    "# define search\n",
    "search = GridSearchCV(model, space, scoring='accuracy', n_jobs=-1, cv=cv)\n",
    "# execute search\n",
    "result = search.fit(_X_train, _y_train)\n",
    "# summarize result\n",
    "print('Best Score: %s' % result.best_score_)\n",
    "print('Best Hyperparameters: %s' % result.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score: 0.783211501597444\n",
      "Best Hyperparameters: {'activation': 'tanh', 'hidden_layer_sizes': (100,), 'learning_rate': 'adaptive'}\n"
     ]
    }
   ],
   "source": [
    "#Non-parametric model\n",
    "#Neural Network\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "#create a neural network classifier with grid search parameters for tuning\n",
    "\n",
    "model = MLPClassifier()\n",
    "# define grid search\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "# define search space\n",
    "space = dict()\n",
    "space['hidden_layer_sizes'] = [(10,30,10),(20,),(50,),(100,)]\n",
    "space['activation'] = ['tanh', 'relu']\n",
    "# space['solver'] = ['lbfgs', 'sgd', 'adam']\n",
    "# space['alpha'] = [0.0001, 0.05]\n",
    "space['learning_rate'] = ['constant','adaptive']\n",
    "# define search\n",
    "search = GridSearchCV(model, space, scoring='accuracy', n_jobs=-1, cv=cv)\n",
    "# execute search\n",
    "result = search.fit(_X_train, _y_train)\n",
    "# summarize result\n",
    "print('Best Score: %s' % result.best_score_)\n",
    "print('Best Hyperparameters: %s' % result.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Model on Test Data for Gaussian Naive Bayes: 0.7090281771132835\n",
      "Final Model on Test Data for MLP Classifier Neural Network: 0.8067855089131685\n"
     ]
    }
   ],
   "source": [
    "final_model_GNB = GaussianNB(var_smoothing=1e-08)\n",
    "final_model_MLP = MLPClassifier(activation='tanh', hidden_layer_sizes=(50,), learning_rate='adaptive')\n",
    "final_model_GNB.fit(_X_final_test, _y_final_test)\n",
    "final_model_MLP.fit(_X_final_test, _y_final_test)\n",
    "print('Final Model on Test Data for Gaussian Naive Bayes:',final_model_GNB.score(_X_final_test, _y_final_test))\n",
    "print('Final Model on Test Data for MLP Classifier Neural Network:',final_model_MLP.score(_X_final_test, _y_final_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Koushik Reddy's code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score: 0.7562597657082003\n",
      "Best Hyperparameters: {'solver': 'svd'}\n"
     ]
    }
   ],
   "source": [
    "#Parametric model\n",
    "#Linear Discriminant Analysis\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "\n",
    "# create an LDA classifier with grid search parameters for tuning\n",
    "model = LinearDiscriminantAnalysis()\n",
    "\n",
    "# define grid search\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "\n",
    "# define search space\n",
    "space = dict()\n",
    "space['solver'] = ['svd', 'lsqr', 'eigen']\n",
    "\n",
    "# define search\n",
    "search = GridSearchCV(model, space, scoring='accuracy', n_jobs=-1, cv=cv)\n",
    "\n",
    "# execute search\n",
    "result = search.fit(_X_train, _y_train)\n",
    "\n",
    "# summarize result\n",
    "print('Best Score: %s' % result.best_score_)\n",
    "print('Best Hyperparameters: %s' % result.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Model on Test Data for Linear Discriminant Analysis: 0.7658045977011494\n"
     ]
    }
   ],
   "source": [
    "# Train and evaluate final model on test data for LDA\n",
    "final_model_LDA = LinearDiscriminantAnalysis(solver='svd')\n",
    "final_model_LDA.fit(_X_final_test, _y_final_test)\n",
    "print('Final Model on Test Data for Linear Discriminant Analysis:', final_model_LDA.score(_X_test, _y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Model on Test Data for Linear Discriminant Analysis: 0.7705577918343876\n"
     ]
    }
   ],
   "source": [
    "# Train and evaluate final model on test data for LDA\n",
    "final_model_LDA = LinearDiscriminantAnalysis(solver='svd')\n",
    "final_model_LDA.fit(_X_final_test, _y_final_test)\n",
    "print('Final Model on Test Data for Linear Discriminant Analysis:', final_model_LDA.score(_X_final_test, _y_final_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score: 0.7822517571884984\n",
      "Best Hyperparameters: {'C': 100, 'kernel': 'rbf'}\n"
     ]
    }
   ],
   "source": [
    "#Non-parametric model\n",
    "# Support Vector Machines (SVM)\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "\n",
    "# create an SVM classifier with grid search parameters for tuning\n",
    "model = SVC()\n",
    "\n",
    "# define grid search\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "\n",
    "# define search space\n",
    "space = dict()\n",
    "space['C'] = [10, 100]\n",
    "space['kernel'] = ['poly', 'rbf', 'sigmoid']\n",
    "\n",
    "# define search\n",
    "search = GridSearchCV(model, space, scoring='accuracy', n_jobs=-1, cv=cv)\n",
    "\n",
    "# execute search\n",
    "result = search.fit(_X_train, _y_train)\n",
    "\n",
    "# summarize result\n",
    "print('Best Score: %s' % result.best_score_)\n",
    "print('Best Hyperparameters: %s' % result.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Model on Test Data for SVC: 0.8148361127084531\n"
     ]
    }
   ],
   "source": [
    "# Train and evaluate final model on test data for SVC\n",
    "final_model_SVC = SVC(C=100, kernel='rbf', gamma='scale', degree=3)\n",
    "final_model_SVC.fit(_X_final_test, _y_final_test)\n",
    "print('Final Model on Test Data for SVC:', final_model_SVC.score(_X_final_test, _y_final_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hao Dian's Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Best Score: 0.784095503460448\n",
      "Logistic Regression Best Parameters: {'C': 1}\n",
      "Logistic Regression Accuracy: 0.7701149425287356\n"
     ]
    }
   ],
   "source": [
    "# logistic regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "model_lr = LogisticRegression()\n",
    "\n",
    "param_grid_lr = {'C': [0.01, 0.1, 1, 10]}\n",
    "\n",
    "grid_lr = GridSearchCV(model_lr, param_grid_lr, cv=5)\n",
    "\n",
    "grid_lr.fit(X_train, y_train)\n",
    "\n",
    "print(\"Logistic Regression Best Score:\", grid_lr.best_score_)\n",
    "print(\"Logistic Regression Best Parameters:\", grid_lr.best_params_)\n",
    "\n",
    "y_pred_lr = grid_lr.predict(X_test)\n",
    "\n",
    "accuracy_lr = accuracy_score(y_test, y_pred_lr)\n",
    "\n",
    "print(\"Logistic Regression Accuracy:\", accuracy_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Best Score: 0.7728477811460742\n",
      "Decision Tree Best Parameters: {'max_depth': 7}\n",
      "Decision Tree Accuracy: 0.7804597701149425\n"
     ]
    }
   ],
   "source": [
    "# decision tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "model_dt = DecisionTreeClassifier()\n",
    "\n",
    "param_grid_dt = {'max_depth': [3, 5, 7, 9]}\n",
    "\n",
    "grid_dt = GridSearchCV(model_dt, param_grid_dt, cv=5)\n",
    "\n",
    "grid_dt.fit(X_train, y_train)\n",
    "\n",
    "print(\"Decision Tree Best Score:\", grid_dt.best_score_)\n",
    "print(\"Decision Tree Best Parameters:\", grid_dt.best_params_)\n",
    "\n",
    "y_pred_dt = grid_dt.predict(X_test)\n",
    "\n",
    "accuracy_dt = accuracy_score(y_test, y_pred_dt)\n",
    "\n",
    "print(\"Decision Tree Accuracy:\", accuracy_dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lihao\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\lihao\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\lihao\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\lihao\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\lihao\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\lihao\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\lihao\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\lihao\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\lihao\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Model on Test Data for Stacking Classifier: 0.8108108108108109\n"
     ]
    }
   ],
   "source": [
    "#Final Model on Test Data for Stacking Classifier\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "estimators = [\n",
    "('lr', LogisticRegression(C=1)),\n",
    "('dt', DecisionTreeClassifier(max_depth=7)),\n",
    "('mlp', MLPClassifier(activation='tanh', hidden_layer_sizes=(50,), learning_rate='adaptive')),\n",
    "('gnb', GaussianNB(var_smoothing=1e-08)),\n",
    "('svc', SVC(C=100, kernel='rbf', gamma='scale', degree=3))]\n",
    "final_model_Stacking = StackingClassifier(estimators=estimators, final_estimator=LogisticRegression(C=0.1))\n",
    "final_model_Stacking.fit(_X_final_test, _y_final_test)\n",
    "print('Final Model on Test Data for Stacking Classifier:', final_model_Stacking.score(_X_final_test, _y_final_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
